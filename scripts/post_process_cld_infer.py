#!/usr/bin/env python3
"""
Post-process CLD inference outputs into a flat ZIP with piccollage-style names.

The output ZIP structure is:

your_zip_file_name.zip
├── piccollage_001_0.png
├── piccollage_002_0.png
├── ...
└── piccollage_064_0.png

Current assumptions and behavior:
- Use `configs/exp001/cld/infer.yaml` (or specified by --config_path) to read:
  - data_dir: JSON generated by pipeline (containing image_path)
  - save_dir: CLD inference outputs (outputs of infer_dlcv.py / cld.infer.inference_layout)
- Rename each "merged" output `save_dir/merged/case_i.png` to `<original_image_name>_0.png`, e.g.:
  - Original: .../piccollage_001.png -> piccollage_001_0.png
  - Original: .../my_image.png      -> my_image_0.png
- Do not output layer_0_rgba etc. sub-layers, you can expand it if needed.
"""

from __future__ import annotations

import argparse
import json
import zipfile
from pathlib import Path
from typing import List, Tuple

import yaml


def _load_cld_config(config_path: Path) -> dict:
    """Load CLD infer config YAML."""
    with config_path.open("r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    if not isinstance(cfg, dict):
        raise ValueError(f"Invalid YAML config: {config_path}")
    return cfg


def _resolve_repo_root(start: Path) -> Path:
    """
    Best-effort repo_root inference, refer to infer_dlcv.py logic:
    - Look up third_party/cld/infer/infer.py
    - If not found, use parents[2] as repo_root
    """
    for p in [start, *start.parents]:
        if (p / "third_party" / "cld" / "infer" / "infer.py").exists():
            return p
    return start.parents[2]


def _load_json_files(data_dir: Path) -> List[Path]:
    """Return sorted list of JSON files in data_dir."""
    if not data_dir.exists():
        raise FileNotFoundError(f"data_dir not found: {data_dir}")
    json_files = sorted(data_dir.glob("*.json"))
    if not json_files:
        raise FileNotFoundError(f"No JSON files found in data_dir: {data_dir}")
    return json_files


def _get_image_stem_from_json(json_path: Path) -> str:
    """
    Read image_path from JSON generated by pipeline_to_cld_infer,
    and return its filename (without extension), e.g. 'piccollage_001'.
    """
    with json_path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    image_path_val = data.get("image_path")
    if not image_path_val:
        raise KeyError(f"'image_path' not found in JSON: {json_path}")
    image_stem = Path(image_path_val).stem
    return image_stem


def _collect_renamed_outputs(
    data_dir: Path,
    save_dir: Path,
) -> List[Tuple[Path, str]]:
    """
    Collect the list of files to write into ZIP according to the order of JSONs in data_dir.

    Returns:
        List[(source_path, arcname)]
        - source_path: actual file location
        - arcname: file name in ZIP (without any sub-folders)
    """
    json_files = _load_json_files(data_dir)

    merged_dir = save_dir / "merged"
    if not merged_dir.exists():
        raise FileNotFoundError(f"'merged' dir not found under save_dir: {merged_dir}")

    results: List[Tuple[Path, str]] = []

    for idx, json_path in enumerate(json_files):
        image_stem = _get_image_stem_from_json(json_path)

        case_name = f"case_{idx}"
        merged_png = merged_dir / f"{case_name}.png"
        if not merged_png.exists():
            raise FileNotFoundError(
                f"Expected merged output not found: {merged_png} "
                f"(for JSON: {json_path})"
            )

        # Currently only output one final merged image, each original image corresponds to *_0.png
        target_name = f"{image_stem}_0.png"
        results.append((merged_png, target_name))

    return results


def _create_zip(
    items: List[Tuple[Path, str]],
    zip_path: Path,
) -> None:
    """Create ZIP file and write all items with given arcnames."""
    zip_path.parent.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
        for src, arcname in items:
            zf.write(src, arcname=arcname)


def main() -> int:
    parser = argparse.ArgumentParser(
        description=(
            "Post-process CLD inference outputs into a flat ZIP with "
            "piccollage-style names (e.g., piccollage_001_0.png)."
        )
    )
    parser.add_argument(
        "--config_path",
        "-c",
        type=str,
        default="configs/exp001/cld/infer.yaml",
        help="CLD inference YAML config path (default: configs/exp001/cld/infer.yaml).",
    )
    parser.add_argument(
        "--output_zip",
        "-o",
        type=str,
        default="cld_inference_postprocessed.zip",
        help="Output ZIP file path (default: cld_inference_postprocessed.zip).",
    )
    args = parser.parse_args()

    script_path = Path(__file__).resolve()
    repo_root = _resolve_repo_root(script_path.parent)

    config_path = Path(args.config_path)
    if not config_path.is_absolute():
        config_path = (repo_root / config_path).resolve()
    if not config_path.exists():
        raise FileNotFoundError(f"Config not found: {config_path}")

    cfg = _load_cld_config(config_path)

    data_dir = Path(cfg["data_dir"])
    if not data_dir.is_absolute():
        data_dir = (repo_root / data_dir).resolve()

    save_dir = Path(cfg["save_dir"])
    if not save_dir.is_absolute():
        save_dir = (repo_root / save_dir).resolve()

    items = _collect_renamed_outputs(data_dir=data_dir, save_dir=save_dir)

    output_zip = Path(args.output_zip)
    if not output_zip.is_absolute():
        output_zip = (repo_root / output_zip).resolve()

    print(f"[INFO] data_dir:  {data_dir}")
    print(f"[INFO] save_dir:  {save_dir}")
    print(f"[INFO] output_zip: {output_zip}")
    print(f"[INFO] Total images to pack: {len(items)}")

    _create_zip(items, output_zip)

    print(f"[INFO] ZIP written to: {output_zip}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


